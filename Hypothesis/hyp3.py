# -*- coding: utf-8 -*-
"""Hyp3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Tg65HOHyXMwa6UEfvXmd2_6nKupZqjhD

The pupose of the code is to test Hyposthesis 3 -
**Bots are more likely to have a default or generic profile setup.**

Data Points: default_profile, default_profile_image, profile_use_background_image, profile_image_url, profile_banner_url.

Check for the presence of default settings and images. A higher incidence of default settings might be indicative of a bot, as human users are more likely to personalize their profiles.



---



---
"""

import numpy as np
import pandas as pd

## allow colab to read from google drive
from google.colab import drive
drive.mount('/content/drive')

##working directory containing the dataset to interact with
data_path = '/content/drive/MyDrive/DSA4263-FinalProject/BotDetection/combined_data.csv'    #please change to your local filepath directory when running

#import data
data_df = pd.read_csv(data_path)

data_df.head()

data_df.info()

#Checking if columns are duplicated
def find_duplicate_columns(df):
    duplicate_columns = []
    columns = df.columns
    for i in range(len(columns)):
        for j in range(i + 1, len(columns)):
            if df[columns[i]].equals(df[columns[j]]):
                duplicate_columns.append((columns[i], columns[j]))
    return duplicate_columns

# Find duplicate columns
duplicate_cols = find_duplicate_columns(data_df)

# Print duplicate columns
if duplicate_cols:
    print("Duplicate columns found:")
    for col1, col2 in duplicate_cols:
        print(f"{col1} is the same as {col2}")
else:
    print("No duplicate columns found.")

#Remove the columns that are not relevant to this
import pandas as pd

columns_to_keep = ['default_profile', 'default_profile_image',
                   'profile_use_background_image', 'profile_image_url',
                   'profile_banner_url','profile_background_image_url_https', 'profile_text_color', 'profile_image_url_https','profile_background_tile',
                   'profile_background_image_url','profile_background_color','Type']

relevant_data_df = data_df[columns_to_keep]

relevant_data_df.head()

relevant_data_df.info()

#Analysing the column information based on Type - Bot vs Genuine

# Filter Bot accounts
bot_data = relevant_data_df[relevant_data_df['Type'] == 'Bot']

# Filter Genuine accounts
genuine_data = relevant_data_df[relevant_data_df['Type'] == 'Genuine']

# Display info for Bot accounts
print("Info for Bot accounts:")
print(bot_data.info())

# Display info for Genuine accounts
print("\nInfo for Genuine accounts:")
print(genuine_data.info())

"""From the output, we can see that the columns 'profile_background_tile', and 'default_profile_image' have relatively low non-null counts across both Bot and Genuine accounts. So we can remove these columns.

Also notice that eceb though 'default_profile' and 'profile_banner_url' have low non-null counts, the distribution is skewed between Bot and Genuine accounts. So we will keep these columns for now.
"""

# Columns to remove
columns_to_remove = ['profile_background_tile', 'default_profile_image']

# Drop the columns from the total dataset
cleaned_data_df = relevant_data_df.drop(columns=columns_to_remove)

# Display info for the cleaned dataset
print("Info for cleaned dataset:")
print(cleaned_data_df.info())

cleaned_data_df.head()

#To load the image urls onto the dataset -

!pip install pillow requests

import requests
from PIL import Image
from io import BytesIO

# Function to download and load image from URL
def load_image_from_url(url):
    if pd.isnull(url):  # Check if URL is empty
        return None
    try:
        response = requests.get(url)
        if response.status_code == 200:  # Check if request is successful
            image = Image.open(BytesIO(response.content))
            return image
        else:
            print(f"Failed to load image from URL (status code {response.status_code}): {url}")
            return None
    except Exception as e:
        print(f"Error loading image from URL: {e}")
        return None

# Apply the function to each URL column
#cleaned_data_df['profile_image'] = cleaned_data_df['profile_image_url'].apply(load_image_from_url)

cleaned_data_df['profile_banner'] = cleaned_data_df['profile_banner_url'].apply(load_image_from_url)

cleaned_data_df['profile_background_image'] = cleaned_data_df['profile_background_image_url_https'].apply(load_image_from_url)

cleaned_data_df['profile_image_https'] = cleaned_data_df['profile_image_url_https'].apply(load_image_from_url)

cleaned_data_df['profile_background'] = cleaned_data_df['profile_background_image_url'].apply(load_image_from_url)

# Display the updated DataFrame
print(cleaned_data_df.head())

# List of columns with URLs
url_columns = ['profile_image_url', 'profile_banner_url', 'profile_background_image_url_https', 'profile_image_url_https', 'profile_background_image_url']

# Drop the columns with URLs from the DataFrame
new_df = cleaned_data_df.drop(columns=url_columns)

# Display the updated DataFrame
print(new_df.head())

#Count the number of missing images

# Function to count missing images in a column
def count_missing_images(column):
    if column is None:
        return 1
    else:
        return 0

# Iterate through each column and count missing images
missing_image_counts = {}
for column in new_df.columns:
    missing_image_counts[column] = new_df[column].apply(count_missing_images).sum()

# Display the missing image counts for each column
for column, count in missing_image_counts.items():
    print(f"Column '{column}': {count} missing images")

# Alternatively, you can display the counts as a DataFrame
missing_image_counts_df = pd.DataFrame.from_dict(missing_image_counts, orient='index', columns=['Missing Image Count'])
print("\nMissing image counts for each column:")
print(missing_image_counts_df)

#Doing the same for each type
# Function to count missing images
def count_missing_images(column_name, df):
    missing_count = df[df[column_name].isna()]['Type'].value_counts()
    return missing_count

# Columns to count missing images for
columns_to_count = ['profile_background_image', 'profile_image', 'profile_banner', 'profile_image_https', 'profile_background']

# Count missing images for each column and based on Type
for column in columns_to_count:
    print(f"Missing images for column '{column}':")
    missing_count = count_missing_images(column, new_df)
    print(missing_count)
    print()

"""From this you can infer that for 'profile_banner' and 'profile_image', our hypotheisis may be correct. But the other columns suggest the opposite"""

new_df.info()

import matplotlib.pyplot as plt

# Function to display images and data for the first 5 rows
def display_images_and_data(df):
    relevant_columns = ['default_profile', 'profile_use_background_image', 'profile_text_color',
                        'profile_background_color', 'Type', 'profile_background_image',
                        'profile_image', 'profile_banner', 'profile_image_https', 'profile_background']

    for idx in range(5):  # Display data for the first 5 rows
        print(f"Row {idx + 1}:")
        row = df.iloc[idx]
        for column in relevant_columns:
            print(f"{column}: {row[column]}")
            if isinstance(row[column], Image.Image):  # Display image if available
                plt.imshow(row[column])
                plt.axis('off')
                plt.title(f"Row {idx + 1} - {column}")
                plt.show()
            else:
                print("No image available")
        print()

# Display images and data for the first 5 rows
display_images_and_data(new_df)



#I susupect that profile_background_image and profile_background are the same and profile_image and profile_image_https are the same.
#To check if i am correct -

def find_duplicate_images(df):
    duplicate_images = []
    columns = df.columns
    for i in range(len(columns)):
        for j in range(i + 1, len(columns)):
            if isinstance(df[columns[i]].iloc[0], Image.Image) and isinstance(df[columns[j]].iloc[0], Image.Image):
                if df[columns[i]].equals(df[columns[j]]):
                    duplicate_images.append((columns[i], columns[j]))
    return duplicate_images

# Find duplicate images in columns
duplicate_image_cols = find_duplicate_images(new_df)

# Print duplicate image columns
if duplicate_image_cols:
    print("Duplicate image columns found:")
    for col1, col2 in duplicate_image_cols:
        print(f"{col1} has the same images as {col2}")
else:
    print("No duplicate image columns found.")

# Drop one of the duplicate image columns
new_df.drop(columns='profile_background_image', inplace=True)

# Confirm the column has been dropped
print(new_df.head())

# Function to convert image objects to hash values
def image_to_hash(image):
    if image is not None:
        return hash(image.tobytes())
    else:
        return None

# Columns containing images
image_columns = ['profile_image', 'profile_banner', 'profile_image_https', 'profile_background']

# Count unique images for each column and by Type
for column in image_columns:
    print(f"Column: {column}")

    # Convert images to hash values
    new_df[column + '_hash'] = new_df[column].apply(image_to_hash)

    # Count unique images for the entire DataFrame
    unique_images_total = new_df[column + '_hash'].nunique()
    print(f"Number of unique images (Total): {unique_images_total}")

    # Count unique images by Type
    unique_images_by_type = new_df.groupby('Type')[column + '_hash'].nunique()
    print("Number of unique images by Type:")
    print(unique_images_by_type)
    print()

"""In general we can see Bots tend to use more of the same images compared to Genuine users. But we need to check these numbers against the available images"""

# Function to convert image objects to hash values
def image_to_hash(image):
    if image is not None:
        return hash(image.tobytes())
    else:
        return None

# Function to count total and unique images for each column
def count_images(df, column):
    # Convert images to hash values
    df[column + '_hash'] = df[column].apply(image_to_hash)

    # Count total images
    total_images = df[column].count()

    # Count unique images
    unique_images = df[column + '_hash'].nunique()

    return total_images, unique_images

# Columns containing images
image_columns = ['profile_image', 'profile_banner', 'profile_image_https', 'profile_background']

# Count unique images for each column and by Type
for column in image_columns:
    print(f"Column: {column}")

    # Count total and unique images
    total_images_total, unique_images_total = count_images(new_df, column)
    print(f"Total images: {total_images_total}")
    print(f"Unique images: {unique_images_total}")

    # Count total and unique images by Type
    total_images_by_type = new_df.groupby('Type')[column].count()
    unique_images_by_type = new_df.groupby('Type')[column + '_hash'].nunique()
    print("Total images by Type:")
    print(total_images_by_type)
    print("Unique images by Type:")
    print(unique_images_by_type)
    print()

import matplotlib.pyplot as plt

# Function to display image
def display_image(image):
    if image is not None:
        plt.imshow(image)
        plt.axis('off')
        plt.show()
    else:
        print("Image not available")

# Display profile background images
for idx, row in cleaned_data_df.iterrows():
    print(f"Index: {idx}")
    display_image(row['profile_background_image'])

#Sanity check

#Analysing the column information based on Type - Bot vs Genuine

# Filter Bot accounts
bot_data = cleaned_data_df[cleaned_data_df['Type'] == 'Bot']

# Filter Genuine accounts
genuine_data = cleaned_data_df[cleaned_data_df['Type'] == 'Genuine']

# Display info for Bot accounts
print("Info for Bot accounts:")
print(bot_data.info())

# Display info for Genuine accounts
print("\nInfo for Genuine accounts:")
print(genuine_data.info())

import pandas as pd

# Assuming your DataFrame is named data_df

# Calculate the threshold for dropping columns
threshold = len(data_df) / 2

# Drop columns with more than half NaN values
data_df_filtered = data_df.dropna(axis=1, thresh=threshold)

# Display the filtered DataFrame
print(data_df_filtered)

data_df_filtered.info()

# Mapping function to encode 'Type' column
data_df_filtered['Bot'] = data_df_filtered['Type'].map({'Bot': 1, 'Genuine': 2})

# Drop the original 'Type' column
data_df_filtered.drop(columns=['Type'], inplace=True)

# Verify the changes
print(data_df_filtered.head())

data_df_filtered.info()

# Fill missing numerical values with median and categorical values with mode
for column in data_df_filtered.columns:
    if data_df_filtered[column].dtype == 'object':  # Categorical
        data_df_filtered[column] = data_df_filtered[column].fillna(data_df_filtered[column].mode().iloc[0])
    else:  # Numerical
        data_df_filtered[column] = data_df_filtered[column].fillna(data_df_filtered[column].median())

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder

# Encode categorical variables
label_encoder = LabelEncoder()
for column in data_df_filtered.select_dtypes(include=['object']).columns:
    data_df_filtered[column] = label_encoder.fit_transform(data_df_filtered[column])

data_df_filtered.info()

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Define features (X) and target variable (y)
X = data_df_filtered.drop(columns=['id', 'name', 'screen_name', 'lang', 'time_zone', 'location', 'profile_image_url',
                                    'profile_background_image_url_https', 'profile_text_color', 'profile_image_url_https',
                                    'profile_sidebar_border_color', 'profile_sidebar_fill_color', 'profile_background_image_url',
                                    'profile_background_color', 'profile_link_color', 'description', 'created_at', 'timestamp',
                                    'crawled_at', 'updated'])
y = data_df_filtered['Bot']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

X_train

# Initialize Random Forest classifier
rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)

# Train the classifier
rf_classifier.fit(X_train, y_train)

# Make predictions on the test set
y_pred = rf_classifier.predict(X_test)

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

y_train

X_test

y_test

